

# Model to use: tiny, base, small, medium, large
# Larger = more accurate but slower
model = "small"

# Language for transcription
# Use ISO 639-1 codes: en, es, fr, de, ja, zh, etc.
language = "en"

# Number of threads for whisper inference
# More threads = faster on multi-core CPUs
threads = 4

# Specific audio device name (partial match)
# Leave empty for auto-detection
# Example: "Microphone" or "Blue Yeti"
device = ""

#
hotkey_mode = "hold"
toggle_timeout_secs = 10   # auto-stop after 10 seconds
  

# Custom voice commands
# Maps spoken phrase -> shell command
# Supports $ENV_VAR expansion (e.g., $TERMINAL, $BROWSER, $EDITOR)
[commands]
# "open terminal" = "kitty"
# "open browser" = "librewolf"
# "open editor" = "emacs"
# "open firefox" = "firefox"
# "screenshot" = "i3-scrot"

# Aliases for common misrecognitions
# Maps what whisper hears -> what you meant
[aliases]
# "e max" = "emacs"
# "fire fox" = "firefox"
# "libre wolf" = "librewolf"
# "kit tea" = "kitty"
